{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import pipeline\n",
    "from sklearn import preprocessing\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomi\\AppData\\Local\\Temp\\ipykernel_2444\\3314996042.py:31: ParserWarning: Both a converter and dtype were specified for column how_tall_in_meters - only the converter will be used.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\tomi\\AppData\\Local\\Temp\\ipykernel_2444\\3314996042.py:31: ParserWarning: Both a converter and dtype were specified for column body_mass_index - only the converter will be used.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\tomi\\AppData\\Local\\Temp\\ipykernel_2444\\3314996042.py:31: ParserWarning: Both a converter and dtype were specified for column z4 - only the converter will be used.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "dtypes = {\n",
    "    \"user\": str,\n",
    "    \"gender\": str,\n",
    "    \"age\": np.int64,\n",
    "    \"how_tall_in_meters\": np.float64,\n",
    "    \"weight\": np.int64,\n",
    "    \"body_mass_index\": np.float64,\n",
    "    \"x1\": np.int64,\n",
    "    \"y1\": np.int64,\n",
    "    \"z1\": np.int64,\n",
    "    \"x2\": np.int64,\n",
    "    \"y2\": np.int64,\n",
    "    \"z2\": np.int64,\n",
    "    \"x3\": np.int64,\n",
    "    \"y3\": np.int64,\n",
    "    \"z3\": np.int64,\n",
    "    \"x4\": np.int64,\n",
    "    \"y4\": np.int64,\n",
    "    \"z4\": np.int64,\n",
    "    \"class\": str,\n",
    "}\n",
    "\n",
    "\n",
    "def errorproofZ4(x):\n",
    "    try:\n",
    "        return np.int64(x)\n",
    "    except ValueError:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"dataset/dataset-HAR-PUC-Rio.csv\",\n",
    "    sep=\";\",\n",
    "    dtype=dtypes,\n",
    "    converters={\n",
    "        \"how_tall_in_meters\": lambda x: np.float64(x.replace(\",\", \".\")),\n",
    "        \"body_mass_index\": lambda x: np.float64(x.replace(\",\", \".\")),\n",
    "        \"z4\": errorproofZ4,\n",
    "    },\n",
    ")\n",
    "\n",
    "profile = ProfileReport(\n",
    "    df[\n",
    "        [\n",
    "            \"x1\",\n",
    "            \"y1\",\n",
    "            \"z1\",\n",
    "            \"x2\",\n",
    "            \"y2\",\n",
    "            \"z2\",\n",
    "            \"x3\",\n",
    "            \"y3\",\n",
    "            \"z3\",\n",
    "            \"x4\",\n",
    "            \"y4\",\n",
    "            \"z4\",\n",
    "        ]\n",
    "    ],\n",
    "    title=\"HAR-PUC measurements profile\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\U_targyak\\ERASMUS\\AI\\hf\\.venv\\lib\\site-packages\\ydata_profiling\\utils\\dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915a59d01988492494dbae747d95c9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cc4164479140c085a1e01997571c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fca5d84a6242f882e31bfacd2a1f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536fb947b36e468fa866e507cdb71da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the only bad value\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e23e07a7b45487e9d9be6be90810beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_profile = ProfileReport(df, title=\"Full HAR-PUC profile\")\n",
    "full_profile.to_widgets()\n",
    "full_profile.to_file(\"full_data_report.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling\n",
    "It is clearly visible, that the data is from a few people.\n",
    "The scale of the variables is very different, but most of them are not very skewed, they mainly show a gaussian distribution, or gaussina mixture distributions.\n",
    "Some of the data seems to be truncated.\n",
    "## Standard Scaling \n",
    "To have all of the data in the same range the measured variables could be transformed to a standard value.\n",
    "Also the user values should be transformed to Standard range, as they are related to the scale of the measured variables. But due to the low number of users only one variable to represent them would be enough, so variables like gender or age or name could be easily dropped.\n",
    "\n",
    "## calss conversion\n",
    "Calsses should be converted to integer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user', 'gender', 'age', 'how_tall_in_meters', 'weight',\n",
       "       'body_mass_index', 'x1', 'y1', 'z1', 'x2', 'y2', 'z2', 'x3', 'y3', 'z3',\n",
       "       'x4', 'y4', 'z4', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sitting': 0, 'sittingdown': 1, 'standing': 2, 'standingup': 3, 'walking': 4}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = {j: i for i, j in enumerate(df[\"class\"].unique())}\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = df.copy()\n",
    "cleaned[\"class\"] = df[\"class\"].apply(lambda x: ids[x])\n",
    "cleaned.drop([\"age\", \"user\", \"gender\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_parquet(\"dataset/unscaled_train_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'user'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 3\u001b[0m cleaned_validation \u001b[39m=\u001b[39m cleaned[cleaned\u001b[39m.\u001b[39;49muser \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjose_carlos\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m cleaned_train \u001b[39m=\u001b[39m cleaned[cleaned\u001b[39m.\u001b[39muser \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mjose_carlos\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n",
      "File \u001b[1;32md:\\U_targyak\\ERASMUS\\AI\\hf\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'user'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cleaned_validation = cleaned[df.user == \"jose_carlos\"]\n",
    "cleaned_train = cleaned[df.user != \"jose_carlos\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_train = cleaned_train.copy()\n",
    "scaled_validation = cleaned_validation.copy()\n",
    "value_columns = [\n",
    "    \"how_tall_in_meters\",\n",
    "    \"weight\",\n",
    "    \"body_mass_index\",\n",
    "    \"x1\",\n",
    "    \"y1\",\n",
    "    \"z1\",\n",
    "    \"x2\",\n",
    "    \"y2\",\n",
    "    \"z2\",\n",
    "    \"x3\",\n",
    "    \"y3\",\n",
    "    \"z3\",\n",
    "    \"x4\",\n",
    "    \"y4\",\n",
    "    \"z4\",\n",
    "]\n",
    "scaled_train[value_columns] = scaler.fit_transform(cleaned_train[value_columns])\n",
    "scaled_validation[value_columns] = scaler.transform(cleaned_validation[value_columns])\n",
    "\n",
    "scaled_train.to_parquet(\"dataset/scaled_train_data.parquet\")\n",
    "scaled_validation.to_parquet(\"dataset/scaled_validation_data.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
